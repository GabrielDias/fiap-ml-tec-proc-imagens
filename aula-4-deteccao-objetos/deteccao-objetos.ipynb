{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentação de imagens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Técnicas para identificação de objetos e formas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.4.3\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "print(cv2.__version__)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificando versão instalada do OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correspondência de formas (*shape matching*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A utilização de contornos para identificação de formas também nos abre possibilidades de comparação entre elas. Somente utilizando aspecto geométrico, é possível identificar formas em imagens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image = cv2.imread(\"imagens/shapes.jpg\")\n",
    "image_target = cv2.imread(\"imagens/star.jpg\")\n",
    "\n",
    "\n",
    "cv2.imshow(\"Fruits\", image)\n",
    "cv2.waitKey()\n",
    "\n",
    "cv2.imshow(\"Target\", image_target)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "_, image_binary = cv2.threshold(image_gray, 230, 255,cv2.THRESH_BINARY_INV)\n",
    "\n",
    "image_gray_target = cv2.cvtColor(image_target, cv2.COLOR_BGR2GRAY)\n",
    "_, image_target_binary = cv2.threshold(image_gray_target, 230, 255,cv2.THRESH_BINARY_INV)\n",
    "\n",
    "\n",
    "cv2.imshow(\"Fruits Binary\", image_binary)\n",
    "cv2.waitKey()\n",
    "\n",
    "cv2.imshow(\"Target Binary\", image_target_binary)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_target_contour = image_target.copy()\n",
    "_, contour_target, hierarchy = cv2.findContours(image_target_binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cv2.drawContours(image_target_contour, contour_target, 0, (0, 255, 0), 2)\n",
    "\n",
    "cv2.imshow(\"Target Contour\", image_target_contour)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21697076862173215\n",
      "0.10479351156122929\n",
      "0.05397178326730856\n",
      "0.24908817898612212\n",
      "0.027009941605979915\n",
      "0.23740218637769916\n"
     ]
    }
   ],
   "source": [
    "image_detected = image.copy()\n",
    "\n",
    "cv2.imshow(\"Detected B\", image_binary)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "_, contours, hierarchy = cv2.findContours(image_binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "for contour in contours:\n",
    "    #Quanto menor o valor mais similaridade existe\n",
    "    match_perc = cv2.matchShapes(contour_target[0], contour, 1, 0)\n",
    "    print(match_perc)\n",
    "    if match_perc < 0.05:\n",
    "        match_contour = contour   \n",
    "        cv2.drawContours(image_detected, [match_contour], 0, (0, 255, 0), 2)\n",
    "        \n",
    "cv2.imshow(\"Detected\", image_detected)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecção de linhas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image = cv2.imread(\"imagens/campo.png\")\n",
    "\n",
    "cv2.imshow(\"Campo Futebol\", image)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-263.           3.0892327]]\n",
      "[[-260.           3.0892327]]\n",
      "[[-15.          3.0892327]]\n",
      "[[-18.          3.0892327]]\n",
      "[[-265.          3.106686]]\n",
      "[[-20.         3.106686]]\n",
      "[[211.          1.5184364]]\n",
      "[[28.         1.5184364]]\n",
      "[[395.          1.5184364]]\n",
      "[[398.          1.5184364]]\n",
      "[[215.          1.5184364]]\n",
      "[[30.         1.5184364]]\n"
     ]
    }
   ],
   "source": [
    "image_gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "image_edges = cv2.Canny(image_gray, 100, 250, apertureSize = 3)\n",
    "\n",
    "cv2.imshow(\"Campo Futebol Edges\", image_edges)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "image_detecada = image.copy()\n",
    "\n",
    "lines = cv2.HoughLines(image_edges, 1, np.pi/180, 100)\n",
    "\n",
    "for line in lines:\n",
    "    print(line)\n",
    "    for rho, theta in line:\n",
    "        a = np.cos(theta)\n",
    "        b = np.sin(theta)\n",
    "        x0 = a*rho\n",
    "        y0 = b*rho\n",
    "        x1 = int(x0 + 1000*(-b))\n",
    "        y1 = int(y0 + 1000*(a))\n",
    "        x2 = int(x0 - 1000*(-b))\n",
    "        y2 = int(y0 - 1000*(a))\n",
    "        cv2.line(image_detecada,(x1,y1),(x2,y2),(0,0,255),2)\n",
    "\n",
    "cv2.imshow(\"Campo Futebol Lines\", image_detecada)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identificação de círculos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image = cv2.imread(\"imagens/moedas.jpg\")\n",
    "\n",
    "cv2.imshow(\"Moedas\", image)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "image_blur = cv2.medianBlur(image_gray, 5)\n",
    "\n",
    "circles = cv2.HoughCircles(image_blur, cv2.HOUGH_GRADIENT, 50, 80)\n",
    " \n",
    "for i in circles[0,:]:\n",
    "    #Círculo em volta da moeda\n",
    "    cv2.circle(image,(i[0], i[1]), i[2], (255, 0, 0), 2) \n",
    "    #Cïrculo no centro da moeda\n",
    "    cv2.circle(image, (i[0], i[1]), 2, (0, 255, 0), 5)\n",
    " \n",
    "cv2.imshow(\"Moedas Detectadas\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deteção de objetos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correspondência por *template*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este tipo de técnica busca por um objeto pré-definido em uma imagem. A forma da busca é como se fosse uma janela que varre a imagem continuamente até o fim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image = cv2.imread(\"imagens/mario.jpg\")\n",
    "cv2.imshow(\"Mario\", image)\n",
    "cv2.waitKey()\n",
    "\n",
    "image_template = cv2.imread(\"imagens/coin_mario.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "cv2.imshow(\"Moeda Template\", image_template)\n",
    "cv2.waitKey()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "image_matched = image.copy()\n",
    "\n",
    "matched_template = cv2.matchTemplate(image_gray, image_template, cv2.TM_CCOEFF_NORMED)\n",
    "w, h = image_template.shape[::-1]\n",
    "\n",
    "threshold = 0.9\n",
    "loc = np.where(matched_template >= threshold)\n",
    "\n",
    "#Índice é a informação da coordenada\n",
    "for pt in zip(*loc[::-1]):\n",
    "    cv2.rectangle(image_matched, pt, (pt[0] + w, pt[1] + h), (0,255,0), 1)\n",
    "\n",
    "cv2.imshow(\"Moeda Matched\", image_matched)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Revisão zip com tuplas\n",
    "#zipper_list = [(1, 'a'), (2, 'b'), (3, 'c')]\n",
    "#list_a, list_b = zip(*zipper_list)\n",
    "#print list_a # (1, 2, 3)\n",
    "#print list_b # ('a', 'b', 'c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"imagens/wally.jpg\")\n",
    "cv2.imshow(\"Wally\", image)\n",
    "cv2.waitKey()\n",
    "\n",
    "image_template = cv2.imread(\"imagens/wally_face.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "cv2.imshow(\"Wally Template\", image_template)\n",
    "cv2.waitKey()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Método para localização de apenas um elemeneto. A função **minMaxLoc** irá trazer o objeto com maior valor de correspondência."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "image_matched = image.copy()\n",
    "\n",
    "matched_template = cv2.matchTemplate(image_gray, image_template, cv2.TM_CCOEFF_NORMED)\n",
    "w, h = image_template.shape[::-1]\n",
    "\n",
    "min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(matched_template)\n",
    "\n",
    "top_left = max_loc\n",
    "bottom_right = (top_left[0] + w, top_left[1] + h)\n",
    "\n",
    "cv2.rectangle(image_matched, top_left, bottom_right, (0,255,0), 2)\n",
    "\n",
    "cv2.imshow(\"Moeda Matched\", image_matched)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SIFT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os algoritmos SIFT e SURF foram patenteados e não estão presentes nas versões oficiais do OpenCV 3.X. Para utilizá-los sem fins lucrativos é preciso instalar um pacote que os habilita, o **opencv-contrib**.\n",
    "\n",
    "No ambiente do Anaconda utilize o comando abaixo:\n",
    "\n",
    "**conda install -c michael_wild opencv-contrib**\n",
    "\n",
    "__https://www.pyimagesearch.com/2015/07/16/where-did-sift-and-surf-go-in-opencv-3/__\n",
    "\n",
    "_Update: a distribuição oficial opencv-contrib removeu os algoritmos patentados. Oficialmente, somente versões 2.X do OpenCV permitem trabalhar com estes algoritmos._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"imagens/cristo.jpg\")\n",
    "cv2.imshow(\"Cristo Redentor\", image)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(3.4.3) C:\\bld\\opencv_1537059099497\\work\\opencv_contrib\\modules\\xfeatures2d\\src\\sift.cpp:1207: error: (-213:The function/feature is not implemented) This algorithm is patented and is excluded in this configuration; Set OPENCV_ENABLE_NONFREE CMake option and rebuild the library in function 'cv::xfeatures2d::SIFT::create'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-97a83707b8e6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mimage_gray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msift_detector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxfeatures2d\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSIFT_create\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mkps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdescs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msift_detector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetectAndCompute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_gray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Pontos detectados \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(3.4.3) C:\\bld\\opencv_1537059099497\\work\\opencv_contrib\\modules\\xfeatures2d\\src\\sift.cpp:1207: error: (-213:The function/feature is not implemented) This algorithm is patented and is excluded in this configuration; Set OPENCV_ENABLE_NONFREE CMake option and rebuild the library in function 'cv::xfeatures2d::SIFT::create'\n"
     ]
    }
   ],
   "source": [
    "image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "sift_detector = cv2.xfeatures2d.SIFT_create()\n",
    "(kps, descs) = sift_detector.detectAndCompute(image_gray, None)\n",
    "print(\"Pontos detectados \" + str(len(kps)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_detected = image.copy()\n",
    "image_detected = cv2.drawKeypoints(image_detected, kps, image_detected, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "cv2.imshow(\"Cristo Redentor Discriminant\", image_detected)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SURF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(3.4.3) C:\\bld\\opencv_1537059099497\\work\\opencv_contrib\\modules\\xfeatures2d\\src\\surf.cpp:1016: error: (-213:The function/feature is not implemented) This algorithm is patented and is excluded in this configuration; Set OPENCV_ENABLE_NONFREE CMake option and rebuild the library in function 'cv::xfeatures2d::SURF::create'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-d7cf556be9e1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mimage_gray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msurf_detector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxfeatures2d\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSURF_create\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0msurf_detector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetHessianThreshold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mkps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdescs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msurf_detector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetectAndCompute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_gray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Pontos detectados \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(3.4.3) C:\\bld\\opencv_1537059099497\\work\\opencv_contrib\\modules\\xfeatures2d\\src\\surf.cpp:1016: error: (-213:The function/feature is not implemented) This algorithm is patented and is excluded in this configuration; Set OPENCV_ENABLE_NONFREE CMake option and rebuild the library in function 'cv::xfeatures2d::SURF::create'\n"
     ]
    }
   ],
   "source": [
    "image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "surf_detector = cv2.xfeatures2d.SURF_create()\n",
    "surf_detector.setHessianThreshold(5000)\n",
    "(kps, descs) = surf_detector.detectAndCompute(image_gray, None)\n",
    "print(\"Pontos detectados \" + str(len(kps)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_detected = image.copy()\n",
    "image_detected = cv2.drawKeypoints(image_detected, kps, image_detected, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "cv2.imshow(\"Cristo Redentor Discriminant\", image_detected)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FAST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pontos detectados 1590\n"
     ]
    }
   ],
   "source": [
    "image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "fast_detector = cv2.FastFeatureDetector_create()\n",
    "kps = fast_detector.detect(image_gray, None)\n",
    "print(\"Pontos detectados \" + str(len(kps)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_detected = image.copy()\n",
    "image_detected = cv2.drawKeypoints(image_detected, kps, image_detected, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "cv2.imshow(\"Cristo Redentor Discriminant\", image_detected)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BRIEF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pontos detectados 1452\n"
     ]
    }
   ],
   "source": [
    "image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "fast_detector = cv2.FastFeatureDetector_create()\n",
    "brief = cv2.xfeatures2d.BriefDescriptorExtractor_create()\n",
    "kps = fast_detector.detect(image_gray, None)\n",
    "kps, desc = brief.compute(image_gray, kps)\n",
    "print(\"Pontos detectados \" + str(len(kps)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_detected = image.copy()\n",
    "image_detected = cv2.drawKeypoints(image_detected, kps, image_detected, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "cv2.imshow(\"Cristo Redentor Discriminant\", image_detected)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ORB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pontos detectados 200\n"
     ]
    }
   ],
   "source": [
    "image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "orb_detector = cv2.ORB_create(200)\n",
    "kps = orb_detector.detect(image_gray, None)\n",
    "kps, desc = orb_detector.compute(image_gray, kps)\n",
    "print(\"Pontos detectados \" + str(len(kps)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_detected = image.copy()\n",
    "image_detected = cv2.drawKeypoints(image_detected, kps, image_detected, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "cv2.imshow(\"Cristo Redentor Discriminant\", image_detected)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correspondência dos descritores com outras imagens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Força bruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_target = cv2.imread(\"imagens/cristo.jpg\")\n",
    "image_target_gray = cv2.cvtColor(image_target, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "image_search = cv2.imread(\"imagens/cristo-redentor.jpg\")\n",
    "image_search_gray = cv2.cvtColor(image_search, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "orb_detector = cv2.ORB_create(5000)\n",
    "\n",
    "kps = orb_detector.detect(image_target_gray, None)\n",
    "kps_target, desc_target = orb_detector.compute(image_target_gray, kps)\n",
    "\n",
    "kps = orb_detector.detect(image_search_gray, None)\n",
    "kps_search, desc_search = orb_detector.compute(image_search_gray, kps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correspondência utilizando Hamming\n",
    "bf = cv2.BFMatcher_create(cv2.NORM_HAMMING, crossCheck=True)\n",
    "\n",
    "#Correspondência dos descritores\n",
    "matches = bf.match(desc_target, desc_search)\n",
    "\n",
    "#Ordenar pela distância dos pontos (similaridaed)\n",
    "matches = sorted(matches, key = lambda x:x.distance)\n",
    "\n",
    "#Obter os 100 pontos detectados\n",
    "image_detected = cv2.drawMatches(image_target_gray, kps_target, image_search_gray, kps_search, matches[:100], None, flags=2)\n",
    "\n",
    "cv2.imshow(\"Cristo Redentor Discriminant\", image_detected)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correspondência por FLAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLANN_INDEX_LSH = 6\n",
    "index_params= dict(algorithm = FLANN_INDEX_LSH, table_number = 6, key_size = 12, multi_probe_level = 1) \n",
    "\n",
    "search_params = dict(checks=50)\n",
    "\n",
    "flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "\n",
    "matches = flann.knnMatch(desc_target, desc_search, k=2)\n",
    "\n",
    "# Need to draw only good matches, so create a mask\n",
    "matchesMask = [[0,0] for i in range(len(matches))]\n",
    "\n",
    "# ratio test as per Lowe's paper\n",
    "for i,(m,n) in enumerate(matches):\n",
    "    if m.distance < 0.8*n.distance:\n",
    "        matchesMask[i]=[1,0]\n",
    "        \n",
    "draw_params = dict(matchColor = (0,255,0), singlePointColor = (255,0,0), matchesMask = matchesMask, flags = 0)\n",
    "image_detected = cv2.drawMatchesKnn(image_target_gray, kps_target, image_search_gray, kps_search, matches, None, **draw_params)\n",
    "\n",
    "cv2.imshow(\"Cristo Redentor Discriminant\", image_detected)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
